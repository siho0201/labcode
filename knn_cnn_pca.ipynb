{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'C:\\\\Users\\\\admin\\\\OneDrive\\\\바탕 화면\\\\code\\\\dataset\\\\image\\\\sample_cw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c79e9961a167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\admin\\OneDrive\\바탕 화면\\code\\dataset\\image\\sample_cw'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다: 'C:\\\\Users\\\\admin\\\\OneDrive\\\\바탕 화면\\\\code\\\\dataset\\\\image\\\\sample_cw'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import os\n",
    "import glob\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_dir = os.chdir(r'C:\\Users\\admin\\OneDrive\\바탕 화면\\code\\dataset\\image\\sample_cw')\n",
    "data_list = glob('*.jpg')\n",
    "\n",
    "random.shuffle(data_list)\n",
    "print(data_list[0:5])\n",
    "print(text_to_word_sequence(data_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "data_height =  32\n",
    "data_width =32\n",
    "channel_n = 3\n",
    "batch_size = len(data_list)\n",
    "images = np.zeros((batch_size, data_height, data_width, channel_n))\n",
    "for n, path in enumerate(data_list[:batch_size]):\n",
    "# lable \n",
    "    token = text_to_word_sequence(data_list[n])\n",
    "    label.append(token[0])\n",
    "# image transform\n",
    "    image = cv2.imread(data_list[n])\n",
    "    image = cv2.resize(image, (32, 32))/255\n",
    "    images[n, :, :, :] =image\n",
    "label = np.array(label)\n",
    "\n",
    "items = label\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "label_encoded = keras.utils.to_categorical(encoder.transform(items))\n",
    "label = label = encoder.transform(items)\n",
    "\n",
    "X =images\n",
    "y = label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:20000]\n",
    "y_train = y[0:20000]\n",
    "\n",
    "X_val = X[20000:24000]\n",
    "y_val = y[20000:24000]\n",
    "\n",
    "X_test = X[24000:]\n",
    "y_test = y[24000:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(data_height, data_width, channel_n)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "es = [EarlyStopping(monitor ='val_loss',mode='min',patience =20), ModelCheckpoint(filepath='best_model.h5',monitor='val_loss',save_best_only=True)]\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "hist = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.ceil(y_pred-0.5)\n",
    "print('y_test:' + str(y_test))\n",
    "print('y_pred:' + str(y_pred))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('cf_matrix:' + str(cf_matrix))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt = '.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "layerIndex = 9\n",
    "func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)\n",
    "layerOutput = func([X])  # input_data is a numpy array\n",
    "print(layerOutput)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(layerOutput)\n",
    "print(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pcax_train,pcax_test,pcay_train,pcay_test = train_test_split(pca_result,label,test_size=0.3,random_state=1004)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=11)\n",
    "classifier.fit(pcax_train, pcay_train)\n",
    "\n",
    "pca_pred = classifier.predict(pcax_test)\n",
    "\n",
    "print(confusion_matrix(pcay_test, pca_pred))\n",
    "print(classification_report(pcay_test, pca_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef7f9a8012d9131766e31894c279374cc63c73121ed4db3b9e67a294a4bf0e74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
